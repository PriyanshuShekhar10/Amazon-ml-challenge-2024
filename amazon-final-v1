{"cells":[{"cell_type":"markdown","metadata":{"id":"wBljO5miq659"},"source":["AMAZON ML CHALLENGE"]},{"cell_type":"markdown","metadata":{"id":"yo80-X92qqBn"},"source":["# INSTALLING ALL LIBRARIES COLLECTIVELY"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18832,"status":"ok","timestamp":1726264657428,"user":{"displayName":"Nalin","userId":"12386870817090352164"},"user_tz":-330},"id":"vCbV911-qnKT","outputId":"d00c24ef-7789-47c1-afbe-3b4a93892559"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting easyocr\n","  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.0+cu121)\n","Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.0+cu121)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n","Collecting python-bidi (from easyocr)\n","  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n","Collecting pyclipper (from easyocr)\n","  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n","Collecting ninja (from easyocr)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n","Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n","Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.6.0\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install easyocr\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3362,"status":"ok","timestamp":1726256516198,"user":{"displayName":"Nalin","userId":"12386870817090352164"},"user_tz":-330},"id":"nroVNCpgsWNt","outputId":"365a1e86-f4b3-4991-e640-1d176ca7adac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.13\n"]}],"source":["!pip install requests pytesseract spacy pillow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7719,"status":"ok","timestamp":1726256523912,"user":{"displayName":"Nalin","userId":"12386870817090352164"},"user_tz":-330},"id":"1lWl9vu1saS-","outputId":"7999466a-e0c6-4f14-baba-18554b1b2d29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 4,816 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n","Fetched 4,816 kB in 2s (2,174 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 123589 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"source":["!sudo apt-get install tesseract-ocr"]},{"cell_type":"markdown","metadata":{"id":"kU70R8DIq_F-"},"source":["# EXTRACTING UNIT GROUPS FROM THE TEST DATA FOR EACH ENTITY"]},{"cell_type":"code","source":[],"metadata":{"id":"MmOUW0629Daz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epmEH_TMsg_m"},"source":["### OCR USING EASY-OCR FOR UNIT EXTRACTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxPb3xY3q_9Q"},"outputs":[],"source":["import requests\n","from PIL import Image, ImageFilter\n","from io import BytesIO\n","import pandas as pd\n","import re\n","import easyocr\n","import cv2 # import the cv2 module\n","import numpy as np # import numpy\n","\n","# Function to download and open an image\n","def download_image(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()  # Raises an error for HTTP errors\n","        return Image.open(BytesIO(response.content))\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Failed to download image from {url}. Error: {e}\")\n","        return None\n","\n","# Load the training data\n","train_data = pd.read_csv('/content/drive/MyDrive/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/train.csv')\n","\n","# Filter the DataFrame to include only rows where entity_name is \"item_weight\"\n","filtered_data = train_data[train_data['entity_name'] == 'item_weight']\n","filtered_data = filtered_data.head(10)\n","\n","# Function to extract number and suffix from entity value\n","def extract_number_and_suffix(entity_value):\n","    match = re.match(r'(\\d+\\.?\\d*)\\s*(\\w+)', entity_value)\n","    if match:\n","        number, suffix = match.groups()\n","        return number, suffix.lower()\n","    return None, None\n","\n","# Initialize EasyOCR Reader\n","reader = easyocr.Reader(['en'], gpu=True)  # Specify language(s) as needed\n","\n","# Array to store results\n","results_array = []\n","\n","# Iterate through each row in the filtered dataframe to extract weights from OCR results\n","for index, row in filtered_data.iterrows():\n","    image_url = row['image_link']  # Assuming the image URL is in a column named 'image_link'\n","\n","    print(f\"Processing image: {image_url}\")\n","\n","    # Download and perform OCR on the image\n","    image = download_image(image_url)\n","\n","    if image is not None:\n","        # Sharpen the image\n","        sharpened_image = image.filter(ImageFilter.SHARPEN)\n","\n","        # Convert PIL image to OpenCV format for EasyOCR\n","        open_cv_image = cv2.cvtColor(np.array(sharpened_image), cv2.COLOR_RGB2BGR)\n","\n","        # Perform OCR using EasyOCR\n","        ocr_result = reader.readtext(open_cv_image, detail=0)\n","        ocr_text = ' '.join(ocr_result)  # Combine list of text lines into a single string\n","\n","        # Extract number and suffix from entity_value column\n","        entity_value = str(row['entity_value'])\n","        number, suffix = extract_number_and_suffix(entity_value)\n","\n","        if number:\n","            # Find the unit that follows the numerical value in the OCR result\n","            unit_pattern = rf'{number}\\s*(\\w+)'\n","            unit_match = re.search(unit_pattern, ocr_text, re.IGNORECASE)\n","            if unit_match:\n","                unit = unit_match.group(1).lower()\n","                print(f\"Found unit '{unit}' for number '{number}'\")\n","                results_array.append((number, unit))\n","            else:\n","                print(f\"No unit found for number '{number}' in OCR result.\")\n","        else:\n","            print(f\"No valid number found in entity_value: {entity_value}\")\n","    else:\n","        print(\"Skipping image due to download error.\\n\")\n","\n","# Output the array of results\n","print(\"\\nFinal extracted values and units:\")\n","print(results_array)\n","\n","# Extract unique units from results_array\n","unique_units = set([unit for _, unit in results_array])\n","\n","print(\"Unique units:\", unique_units)"]},{"cell_type":"markdown","metadata":{"id":"v8iPut82rAqL"},"source":["#VERIFYING FOR EACH UNITS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FLXIYOrrjpO"},"outputs":[],"source":["units  = {'lb', 'lbs', 'pound', 'pounds', 'lb.', 'lbs.', 'pd', 'pds', 'pd.', 'pnd', 'pondo',\n","    'kg', 'kgs', 'kilogram', 'kilograms', 'kilo', 'kilos', 'kg.', 'kgs.', 'kilogramme', 'kilogrammes',\n","    'kilog', 'kgr', 'kgram', 'kgrm','g', 'gm', 'gms', 'gram', 'grams', 'gramme', 'grammes', 'g.', 'gm.', 'gms.', 'grm', 'grms', 'gr.', 'gmme'\n"," }\n","\n","# Extract unique units from results_array\n","rejected_units = set([unit for _, unit in results_array])\n","\n","print(\"Unique units:\", unique_units)\n","\n","# Human in the loop - Manual review and selection\n","selected_units = []\n","rejected_units = []\n","\n","for unit in unique_units:\n","    print(f\"\\nUnit: {unit}\")\n","    choice = input(\"Select (s) or Reject (r)? \")\n","    if choice.lower() == 's':\n","        selected_units.append(unit)\n","    elif choice.lower() == 'r':\n","        rejected_units.append(unit)\n","    else:\n","        print(\"Invalid choice. Skipping.\")\n","\n","print(\"\\nSelected units:\", selected_units)\n","print(\"Rejected units:\", rejected_units)\n"]},{"cell_type":"markdown","metadata":{"id":"gc-FrLwerkN3"},"source":["# FINAL UNITS FOR EACH ENTITY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRQtpU9IrrCF"},"outputs":[],"source":["volume_units = [\n","    'ml', 'milliliter', 'millilitre', 'liters', 'litres', 'liter', 'litre',\n","    'gallon', 'gallons', 'cu cm', 'cubic centimeter', 'cubic centimetre',\n","    'cu m', 'cubic meter', 'cubic metre', 'cu inch', 'cubic inch', 'cu ft',\n","    'cubic foot', 'cubic feet', 'fl oz', 'fluid ounce', 'fluid ounces'\n","]\n","\n","dimension_units = [\n","    'cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet','\"', \"'\"\n","]\n","\n","wattage_units = [\n","    'w', 'watt', 'watts', 'w.', 'wtt', 'wtts', 'kw', 'kilowatt', 'kilowatts', 'mw', 'megawatt', 'megawatts'\n","]\n","\n","voltage_units = [\n","    'v', 'volt', 'volts', 'v.', 'vol', 'voltage', 'voltages'\n","]"]},{"cell_type":"markdown","metadata":{"id":"mKKBhpBYr4Mi"},"source":["# FUNCTION TO GET THE ENTITY VALUE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20711,"status":"ok","timestamp":1726237020941,"user":{"displayName":"Nalin","userId":"12386870817090352164"},"user_tz":-330},"id":"usg1W1G_sGsh","outputId":"07b22816-befd-4628-ef0f-7a2ba7c869cd"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n","WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"]},{"name":"stdout","output_type":"stream","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"name":"stderr","output_type":"stream","text":["WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"]},{"name":"stdout","output_type":"stream","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n","/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(model_path, map_location=device)\n"]}],"source":["import re\n","import easyocr\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","import cv2\n","import numpy as np\n","\n","# Define the unit variations for different entities\n","unit_variations = {\n","    'item_weight': [\n","        'lb', 'lbs', 'pound', 'pounds', 'lb.', 'lbs.', 'pd', 'pds', 'pd.', 'pnd', 'pondo',\n","        'kg', 'kgs', 'kilogram', 'kilograms', 'kilo', 'kilos', 'kg.', 'kgs.', 'kilogramme', 'kilogrammes',\n","        'kilog', 'kgr', 'kgram', 'kgrm', 'g', 'gm', 'gms', 'gram', 'grams', 'gramme', 'grammes', 'g.', 'gm.', 'gms.',\n","        'grm', 'grms', 'gr.', 'gmme', 'oz', 'ounce', 'ounces', 'oz.', 'ozs', 'ozs.'\n","    ],\n","    'maximum_weight_recommendation': [\n","        'lb', 'lbs', 'pound', 'pounds', 'lb.', 'lbs.', 'pd', 'pds', 'pd.', 'pnd', 'pondo',\n","        'kg', 'kgs', 'kilogram', 'kilograms', 'kilo', 'kilos', 'kg.', 'kgs.', 'kilogramme', 'kilogrammes',\n","        'kilog', 'kgr', 'kgram', 'kgrm', 'g', 'gm', 'gms', 'gram', 'grams', 'gramme', 'grammes', 'g.', 'gm.', 'gms.',\n","        'grm', 'grms', 'gr.', 'gmme', 'oz', 'ounce', 'ounces', 'oz.', 'ozs', 'ozs.'\n","    ],\n","    'voltage': ['v', 'volt', 'volts', 'v.', 'vol', 'voltage', 'voltages'],\n","    'wattage': ['w', 'watt', 'watts', 'w.', 'wtt', 'wtts', 'kw', 'kilowatt', 'kilowatts', 'mw', 'megawatt', 'megawatts'],\n","    'height': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'depth': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'width': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'item_volume': [\n","        'ml', 'milliliter', 'millilitre', 'liters', 'litres', 'liter', 'litre',\n","        'gallon', 'gallons', 'cu cm', 'cubic centimeter', 'cubic centimetre',\n","        'cu m', 'cubic meter', 'cubic metre', 'cu inch', 'cubic inch', 'cu ft',\n","        'cubic foot', 'cubic feet', 'fl oz', 'fluid ounce', 'fluid ounces'\n","    ]\n","}\n","\n","# Initialize EasyOCR Reader\n","reader = easyocr.Reader(['en'], gpu=True)  # Using GPU if available\n","\n","# Function to download and open an image\n","def download_image(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()  # Raises an error for HTTP errors\n","        return Image.open(BytesIO(response.content))\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Failed to download image from {url}. Error: {e}\")\n","        return None\n","\n","# Function to extract the first number and its corresponding unit from OCR text\n","def extract_first_number_with_unit(ocr_result, entity_name):\n","    # Combine OCR results into a single string\n","    ocr_text = ' '.join(ocr_result)\n","\n","    # Normalize numbers by removing spaces within numbers (e.g., '1,500' should remain '1,500')\n","    ocr_text = re.sub(r'(\\d),(\\d)', r'\\1\\2', ocr_text)  # Remove commas in numbers\n","\n","    # Use regex to find all occurrences of numbers (including those with commas) and following words\n","    matches = re.findall(r'(\\d+\\.?\\d*|\\d{1,3}(?:,\\d{3})*)\\s*(\\w+)?', ocr_text)\n","\n","    # Fetch the relevant units for the specified entity\n","    relevant_units = unit_variations.get(entity_name, [])\n","\n","    for number, word in matches:\n","        # Check if the following word is a recognized unit\n","        if word and word.lower() in relevant_units:\n","            return number.replace(',', ''), word.lower()  # Remove commas for the numeric value\n","\n","    # If no unit matches, return the first detected number\n","    if matches:\n","        return matches[0][0].replace(',', ''), None  # Remove commas for the numeric value\n","\n","    # If no numbers are found, return None\n","    return None, None\n","\n","# Main function to get the entity value from an image\n","def extract_entity_value(image_url, entity_name):\n","    # Download the image\n","    image = download_image(image_url)\n","\n","    if image:\n","        # Convert PIL image to OpenCV format for EasyOCR\n","        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","\n","        # Perform OCR using EasyOCR\n","        ocr_result = reader.readtext(open_cv_image, detail=0)\n","\n","        # Extract the first number with its corresponding unit (if any)\n","        number, unit = extract_first_number_with_unit(ocr_result, entity_name)\n","\n","        if unit:\n","            return f\"First number with matching {entity_name} unit: {number} {unit}\"\n","        elif number:\n","            return f\"First number without matching unit: {number}\"\n","        else:\n","            return \"No number found.\"\n","    else:\n","        return \"Failed to process the image.\"\n","\n"]},{"cell_type":"markdown","source":["# easy ocr with unit standardization"],"metadata":{"id":"yju6JW-6XS7y"}},{"cell_type":"code","source":["import re\n","import easyocr\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","import cv2\n","import numpy as np\n","\n","# Define the unit variations for different entities\n","unit_variations = {\n","    'item_weight': [\n","        'lb', 'lbs', 'pound', 'pounds', 'lb.', 'lbs.', 'pd', 'pds', 'pd.', 'pnd', 'pondo',\n","        'kg', 'kgs', 'kilogram', 'kilograms', 'kilo', 'kilos', 'kg.', 'kgs.', 'kilogramme', 'kilogrammes',\n","        'kilog', 'kgr', 'kgram', 'kgrm', 'g', 'gm', 'gms', 'gram', 'grams', 'gramme', 'grammes', 'g.', 'gm.', 'gms.',\n","        'grm', 'grms', 'gr.', 'gmme', 'oz', 'ounce', 'ounces', 'oz.', 'ozs', 'ozs.'\n","    ],\n","    'maximum_weight_recommendation': [\n","        'lb', 'lbs', 'pound', 'pounds', 'lb.', 'lbs.', 'pd', 'pds', 'pd.', 'pnd', 'pondo',\n","        'kg', 'kgs', 'kilogram', 'kilograms', 'kilo', 'kilos', 'kg.', 'kgs.', 'kilogramme', 'kilogrammes',\n","        'kilog', 'kgr', 'kgram', 'kgrm', 'g', 'gm', 'gms', 'gram', 'grams', 'gramme', 'grammes', 'g.', 'gm.', 'gms.',\n","        'grm', 'grms', 'gr.', 'gmme', 'oz', 'ounce', 'ounces', 'oz.', 'ozs', 'ozs.'\n","    ],\n","    'voltage': ['v', 'volt', 'volts', 'v.', 'vol', 'voltage', 'voltages'],\n","    'wattage': ['w', 'watt', 'watts', 'w.', 'wtt', 'wtts', 'kw', 'kilowatt', 'kilowatts', 'mw', 'megawatt', 'megawatts'],\n","    'height': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'depth': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'width': ['cm', 'mm', 'inch', 'inches', 'm', 'meter', 'meters', 'ft', 'foot', 'feet', '\"', \"'\"],\n","    'item_volume': [\n","        'ml', 'milliliter', 'millilitre', 'liters', 'litres', 'liter', 'litre',\n","        'gallon', 'gallons', 'cu cm', 'cubic centimeter', 'cubic centimetre',\n","        'cu m', 'cubic meter', 'cubic metre', 'cu inch', 'cubic inch', 'cu ft',\n","        'cubic foot', 'cubic feet', 'fl oz', 'fluid ounce', 'fluid ounces'\n","    ]\n","}\n","\n","# Entity to allowed units mapping\n","entity_unit_map = {\n","    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n","    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n","    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n","    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n","    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n","    'voltage': {'kilovolt', 'millivolt', 'volt'},\n","    'wattage': {'kilowatt', 'watt'},\n","    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n","                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n","}\n","\n","allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n","\n","# Unit conversion mapping\n","unit_conversion_map = {\n","    'lb': ('pound', 1),\n","    'lbs': ('pound', 1),\n","    'pounds': ('pound', 1),\n","    'oz': ('ounce', 1),\n","    'ounces': ('ounce', 1),\n","    'kg': ('kilogram', 1),\n","    'kgs': ('kilogram', 1),\n","    'g': ('gram', 1),\n","    'grams': ('gram', 1),\n","    'cm': ('centimetre', 1),\n","    'mm': ('millimetre', 1),\n","    'm': ('metre', 1),\n","    'ft': ('foot', 1),\n","    'inch': ('inch', 1),\n","    'v': ('volt', 1),\n","    'w': ('watt', 1),\n","    'kw': ('kilowatt', 1),\n","    'ml': ('millilitre', 1),\n","    'liters': ('litre', 1),\n","    'cu cm': ('cubic centimetre', 1),\n","    'cu m': ('cubic metre', 1),\n","    'cu inch': ('cubic inch', 1),\n","    'cu ft': ('cubic foot', 1),\n","    'fl oz': ('fluid ounce', 1),\n","}\n","\n","# Initialize EasyOCR Reader\n","reader = easyocr.Reader(['en'], gpu=True)  # Using GPU if available\n","\n","# Function to download and open an image\n","def download_image(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()  # Raises an error for HTTP errors\n","        return Image.open(BytesIO(response.content))\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Failed to download image from {url}. Error: {e}\")\n","        return None\n","\n","# Function to convert units to allowed units\n","def convert_to_allowed_unit(number, unit, entity_name):\n","    unit = unit.lower()\n","\n","    # Convert unit if necessary\n","    if unit in unit_conversion_map:\n","        converted_unit, factor = unit_conversion_map[unit]\n","        if converted_unit in entity_unit_map[entity_name]:\n","            return float(number) * factor, converted_unit\n","    return number, unit\n","\n","# Function to extract the first number and its corresponding unit from OCR text\n","def extract_first_number_with_unit(ocr_result, entity_name):\n","    # Combine OCR results into a single string\n","    ocr_text = ' '.join(ocr_result)\n","\n","    # Normalize numbers by removing spaces within numbers (e.g., '1,500' should remain '1,500')\n","    ocr_text = re.sub(r'(\\d),(\\d)', r'\\1\\2', ocr_text)  # Remove commas in numbers\n","\n","    # Use regex to find all occurrences of numbers (including those with commas) and following words\n","    matches = re.findall(r'(\\d+\\.?\\d*|\\d{1,3}(?:,\\d{3})*)\\s*(\\w+)?', ocr_text)\n","\n","    # Fetch the relevant units for the specified entity\n","    relevant_units = entity_unit_map.get(entity_name, set())\n","\n","    for number, word in matches:\n","        # Check if the following word is a recognized unit\n","        if word:\n","            # Convert to an allowed unit\n","            converted_number, converted_unit = convert_to_allowed_unit(number.replace(',', ''), word, entity_name)\n","\n","            if converted_unit in relevant_units:\n","                return converted_number, converted_unit\n","\n","    # If no unit matches, return None\n","    return None, None\n","\n","# Main function to get the entity value from an image\n","def extract_entity_value(image_url, entity_name):\n","    # Download the image\n","    image = download_image(image_url)\n","\n","    if image:\n","        # Convert PIL image to OpenCV format for EasyOCR\n","        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","\n","        # Perform OCR using EasyOCR\n","        ocr_result = reader.readtext(open_cv_image, detail=0)\n","\n","        # Extract the first number with its corresponding unit (if any)\n","        number, unit = extract_first_number_with_unit(ocr_result, entity_name)\n","\n","        if unit:\n","            return f\"First number with matching {entity_name} unit: {number} {unit}\"\n","        elif number:\n","            return f\"First number without matching unit: {number}\"\n","        else:\n","            return \"No number found.\"\n","    else:\n","        return \"Failed to process the image.\"\n"],"metadata":{"id":"CQJ09NodXSK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726247652719,"user_tz":-330,"elapsed":13811,"user":{"displayName":"Nalin","userId":"12386870817090352164"}},"outputId":"06c068e3-e7d1-4629-e29f-6780360d8a14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"]},{"output_type":"stream","name":"stdout","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"output_type":"stream","name":"stderr","text":["WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"]},{"output_type":"stream","name":"stdout","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n","/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path, map_location=device))\n"]}]},{"cell_type":"markdown","source":["NEW LATEST"],"metadata":{"id":"8UM5HospMnAl"}},{"cell_type":"code","source":["import re\n","import easyocr\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","import cv2\n","import numpy as np\n","\n","# (Existing code for unit definitions and OCR setup remains unchanged)\n","\n","# Function to extract the first number and its corresponding unit from OCR text\n","def extract_first_number_with_unit(ocr_result, entity_name):\n","    # Combine OCR results into a single string\n","    ocr_text = ' '.join(ocr_result)\n","\n","    # Normalize numbers by removing spaces within numbers (e.g., '1,500' should remain '1,500')\n","    ocr_text = re.sub(r'(\\d),(\\d)', r'\\1\\2', ocr_text)  # Remove commas in numbers\n","\n","    # Use regex to find all occurrences of numbers (including those with commas) and following words\n","    matches = re.findall(r'(\\d+\\.?\\d*|\\d{1,3}(?:,\\d{3})*)\\s*(\\w+)?', ocr_text)\n","\n","    # Fetch the relevant units for the specified entity\n","    relevant_units = entity_unit_map.get(entity_name, set())\n","\n","    # Attempt to find a number with a unit\n","    for number, word in matches:\n","        # Check if the following word is a recognized unit\n","        if word:\n","            # Convert to an allowed unit\n","            converted_number, converted_unit = convert_to_allowed_unit(number.replace(',', ''), word, entity_name)\n","\n","            if converted_unit in relevant_units:\n","                return converted_number, converted_unit\n","\n","    # If no unit matches, try to detect unit in the whole text\n","    detected_unit = None\n","    for unit in relevant_units:\n","        if unit in ocr_text.lower():  # Check if any allowed unit is present in the text\n","            detected_unit = unit\n","            break\n","\n","    # If a unit is found in the text but not directly associated with a number\n","    if detected_unit:\n","        for number, word in matches:\n","            if word is None:  # If there's a number without an accompanying unit\n","                return number, detected_unit\n","\n","    # If no number or unit match is found\n","    return None, None\n","\n","# Function to download and open an image\n","def download_image(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()  # Raises an error for HTTP errors\n","        return Image.open(BytesIO(response.content))\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Failed to download image from {url}. Error: {e}\")\n","        return None\n","\n","# Main function to get the entity value from an image\n","def extract_entity_value(image_url, entity_name):\n","    # Download the image\n","    image = download_image(image_url)\n","\n","    if image:\n","        # Convert PIL image to OpenCV format for EasyOCR\n","        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","\n","        # Perform OCR using EasyOCR\n","        ocr_result = reader.readtext(open_cv_image, detail=0)\n","\n","        # Extract the first number with its corresponding unit (if any)\n","        number, unit = extract_first_number_with_unit(ocr_result, entity_name)\n","\n","        if unit:\n","            return f\"First number with matching {entity_name} unit: {number} {unit}\"\n","        elif number:\n","            return f\"First number without matching unit: {number}\"\n","        else:\n","            return \"No number found.\"\n","    else:\n","        return \"Failed to process the image.\"\n"],"metadata":{"id":"uwK_CgS8MEmW","executionInfo":{"status":"ok","timestamp":1726264674642,"user_tz":-330,"elapsed":17216,"user":{"displayName":"Nalin","userId":"12386870817090352164"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install re"],"metadata":{"id":"MaHhXN-tXiy7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FUNCTION WITH UNITLESS TO UNIT CONVERSION"],"metadata":{"id":"xcjC8uTgvyb1"}},{"cell_type":"code","source":["import re\n","import easyocr\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","import cv2\n","import numpy as np\n","\n","# Define the unit variations for different entities\n","unit_variations = {\n","    # (your existing unit variations here)\n","}\n","\n","# Entity to allowed units mapping\n","entity_unit_map = {\n","    # (your existing entity to unit mapping here)\n","}\n","\n","allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n","\n","# Unit conversion mapping\n","unit_conversion_map = {\n","    # (your existing unit conversion mapping here)\n","}\n","\n","# Most common units for each entity_name\n","default_units = {\n","    'depth': 'centimetre',\n","    'height': 'centimetre',\n","    'item_volume': 'millilitre',\n","    'item_weight': 'gram',\n","    'maximum_weight_recommendation': 'kilogram',\n","    'voltage': 'volt',\n","    'wattage': 'watt',\n","    'width': 'centimetre'\n","}\n","\n","# Initialize EasyOCR Reader\n","reader = easyocr.Reader(['en'], gpu=True)  # Using GPU if available\n","\n","# Function to download and open an image\n","def download_image(url):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        response.raise_for_status()  # Raises an error for HTTP errors\n","        return Image.open(BytesIO(response.content))\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Failed to download image from {url}. Error: {e}\")\n","        return None\n","\n","# Function to convert units to allowed units\n","def convert_to_allowed_unit(number, unit, entity_name):\n","    unit = unit.lower()\n","\n","    # Convert unit if necessary\n","    if unit in unit_conversion_map:\n","        converted_unit, factor = unit_conversion_map[unit]\n","        if converted_unit in entity_unit_map[entity_name]:\n","            return float(number) * factor, converted_unit\n","    return number, unit\n","\n","# Function to extract the first number and its corresponding unit from OCR text\n","def extract_first_number_with_unit(ocr_result, entity_name):\n","    # previous code ...\n","    numbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","    units = ['cm', 'mm', 'm', 'inches', '\"', 'feet', \"'\", 'gram', 'kg', 'liter', 'litre', 'ml', 'oz', 'pound', 'lb']\n","    # Check if ocr_result is a list\n","    if isinstance(ocr_result, list):\n","        # If it's a list, join its elements into a single string\n","        text = ' '.join(ocr_result).lower()\n","    else:\n","        # If it's already a string, just convert to lowercase\n","        text = ocr_result.lower()\n","\n","    # Initialize number to None to handle cases where no number is found\n","# ... remaining code\n","\n","    # Initialize number to None to handle cases where no number is found\n","    number = None\n","\n","    if any(num in text for num in numbers):\n","        for i in range(len(text)):\n","            if text[i] in numbers:\n","                num = text[i]\n","                j = i + 1\n","                while j < len(text) and (text[j] in numbers or text[j] == '.'):\n","                    num += text[j]\n","                    j += 1\n","\n","                # Check for unit after the number\n","                unit = None\n","                if j < len(text) and text[j] == ' ':\n","                    for k in range(j + 1, len(text)):\n","                        if text[k] != ' ':\n","                            possible_unit = text[k:]\n","                            for u in units:\n","                                if u in possible_unit:\n","                                    unit = u\n","                                    break\n","                            break\n","\n","                # Return the number and unit if found\n","                if unit:\n","                    return num, unit\n","                else:\n","                    # If no unit matches, return the number with None for the unit\n","                    return num, None\n","    # Return None, None if no number is found in the text\n","    return None, None\n","\n","# Main function to get the entity value from an image\n","def extract_entity_value(image_url, entity_name):\n","    # Download the image\n","    image = download_image(image_url)\n","\n","    if image:\n","        # Convert PIL image to OpenCV format for EasyOCR\n","        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n","\n","        # Perform OCR using EasyOCR\n","        ocr_result = reader.readtext(open_cv_image, detail=0)\n","\n","        # Extract the first number with its corresponding unit (if any)\n","        number, unit = extract_first_number_with_unit(ocr_result, entity_name)\n","\n","        if unit:\n","            return f\"First number with matching {entity_name} unit: {number} {unit}\"\n","        elif number:\n","            # Use the default unit if no unit was found\n","            default_unit = default_units.get(entity_name, '')\n","            return f\"First number without matching unit: {number} {default_unit}\"\n","        else:\n","            return \"No number found.\"\n","    else:\n","        return \"Failed to process the image.\"\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEF51d2Fv4tN","executionInfo":{"status":"ok","timestamp":1726264302819,"user_tz":-330,"elapsed":13727,"user":{"displayName":"Nalin","userId":"12386870817090352164"}},"outputId":"20cc3c31-8359-44de-9033-5aba11887396"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n","WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"]},{"output_type":"stream","name":"stdout","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"output_type":"stream","name":"stderr","text":["WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"]},{"output_type":"stream","name":"stdout","text":["Progress: |██████████████████████████████████████████████████| 100.0% Complete"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n","/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(model_path, map_location=device)\n"]}]},{"cell_type":"markdown","source":["# FUNCTION USING INTERNVL HUGGINGFACE"],"metadata":{"id":"9dvCzmHt5OCA"}},{"cell_type":"markdown","metadata":{"id":"R8ZwUf2esG3j"},"source":["# EXAMPLE USAGE OF FUNCTION"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21813,"status":"ok","timestamp":1726264344312,"user":{"displayName":"Nalin","userId":"12386870817090352164"},"user_tz":-330},"id":"XnUHAasNsLLG","outputId":"0c7bd2d7-cc76-4fb2-dc6e-7d85a0299d9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["First number without matching unit: 24.12 millilitre\n"]}],"source":["# Example usage\n","image_link = 'https://m.media-amazon.com/images/I/61nLdfZCTxL.jpg'\n","entity_name = 'item_volume'\n","result = extract_entity_value(image_link, entity_name)\n","print(result)\n"]},{"cell_type":"markdown","metadata":{"id":"zqRXaPfDsLpD"},"source":[]},{"cell_type":"markdown","metadata":{"id":"NJ_nfaaIwDR3"},"source":["# CALLING FUNCTION FOR EACH IMAGE"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"id":"DUGF61CHwjbw","outputId":"d5ee75fb-087a-4492-80aa-68e0c9408e8d","executionInfo":{"status":"error","timestamp":1726264529278,"user_tz":-330,"elapsed":181161,"user":{"displayName":"Nalin","userId":"12386870817090352164"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Image: https://m.media-amazon.com/images/I/61I9XdN6OFL.jpg, Entity: item_weight, Result: First number without matching unit: 100 gram\n","Image: https://m.media-amazon.com/images/I/71gSRbyXmoL.jpg, Entity: item_volume, Result: First number with matching item_volume unit: 62 m\n","Image: https://m.media-amazon.com/images/I/61BZ4zrjZXL.jpg, Entity: item_weight, Result: First number with matching item_weight unit: 0.709 cm\n","Image: https://m.media-amazon.com/images/I/612mrlqiI4L.jpg, Entity: item_weight, Result: First number without matching unit: 3 gram\n","Image: https://m.media-amazon.com/images/I/617Tl40LOXL.jpg, Entity: item_weight, Result: First number without matching unit: 1400 gram\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-583fffc29206>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mentity_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_entity_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image: {image_link}, Entity: {entity_name}, Result: {result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-cbd6e65b4274>\u001b[0m in \u001b[0;36mextract_entity_value\u001b[0;34m(image_url, entity_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Perform OCR using EasyOCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mocr_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_cv_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Extract the first number with its corresponding unit (if any)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mreadtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         horizontal_list, free_list = self.detect(img, \n\u001b[0m\u001b[1;32m    457\u001b[0m                                                  \u001b[0mmin_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                                  \u001b[0mlow_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         text_box_list = self.get_textbox(self.detector, \n\u001b[0m\u001b[1;32m    322\u001b[0m                                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                     \u001b[0mcanvas_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mestimate_num_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_num_chars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     bboxes_list, polys_list = test_net(canvas_size, mag_ratio, detector,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                        \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                        \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mboxes_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolys_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/craft.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\" Base network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"\"\" U network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/model/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mh_relu2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# prompt: call the function  extract_entity_value(image_link, entity_name)\n","# get the value of image_link, entity_name from train_data = pd.read_csv('/content/drive/MyDrive/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/train.csv')\n","\n","import pandas as pd\n","# Load the training data\n","train_data = pd.read_csv('/content/drive/MyDrive/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/train.csv').head(100)\n","\n","# Iterate through each row in the dataframe\n","for index, row in train_data.iterrows():\n","    image_link = row['image_link']\n","    entity_name = row['entity_name']\n","    result = extract_entity_value(image_link, entity_name)\n","    print(f\"Image: {image_link}, Entity: {entity_name}, Result: {result}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bf93ye4Uw1NL"},"outputs":[],"source":["# prompt: OUTPUT FRACTION OF THE ROWS FOR WHICH THERE WAS A NUMBER FOUND\n","\n","import pandas as pd\n","# Load the training data\n","train_data = pd.read_csv('/content/drive/MyDrive/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/train.csv').sample(n=100, random_state=41)\n","\n","# Initialize a counter for successful extractions\n","number_found_count = 0\n","\n","# Iterate through each row in the dataframe\n","for index, row in train_data.iterrows():\n","    image_link = row['image_link']\n","    entity_name = row['entity_name']\n","    result = extract_entity_value(image_link, entity_name)\n","    if \"No number found\" not in result:\n","        number_found_count += 1\n","    print(f\"Image: {image_link}, Entity: {entity_name}, Result: {result}\")\n","\n","# Calculate the fraction of rows with numbers found\n","fraction_number_found = number_found_count / len(train_data)\n","\n","print(f\"\\nFraction of rows with numbers found: {fraction_number_found}\")\n"]},{"cell_type":"code","source":["# prompt: compare the predicted entity_value with the given entity_value side by side\n","\n","import pandas as pd\n","# Load the training data\n","train_data = pd.read_csv('/content/drive/MyDrive/66e31d6ee96cd_student_resource_3/student_resource 3/dataset/train.csv').sample(n=100, random_state=41)\n","\n","# Initialize a counter for successful extractions\n","number_found_count = 0\n","\n","# Create lists to store results\n","predicted_values = []\n","actual_values = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in train_data.iterrows():\n","    image_link = row['image_link']\n","    entity_name = row['entity_name']\n","    actual_value = row['entity_value']\n","    result = extract_entity_value(image_link, entity_name)\n","\n","    # Store predicted and actual values\n","    predicted_values.append(result)\n","    actual_values.append(actual_value)\n","\n","    if \"No number found\" not in result:\n","        number_found_count += 1\n","    print(f\"Image: {image_link}, Entity: {entity_name}, Result: {result}, Actual: {actual_value}\")\n","\n","# Calculate the fraction of rows with numbers found\n","fraction_number_found = number_found_count / len(train_data)\n","\n","print(f\"\\nFraction of rows with numbers found: {fraction_number_found}\")\n","\n","# Create a DataFrame for side-by-side comparison\n","comparison_df = pd.DataFrame({'Predicted Value': predicted_values, 'Actual Value': actual_values})\n","\n","# Display the comparison DataFrame\n","print(comparison_df)\n"],"metadata":{"id":"ixp0e5CWX4RL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison_df.head(100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"P_lldj1tY9b_","executionInfo":{"status":"ok","timestamp":1726247865834,"user_tz":-330,"elapsed":460,"user":{"displayName":"Nalin","userId":"12386870817090352164"}},"outputId":"54596287-9ebb-4077-a01a-8e6ba0f5de35"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      Predicted Value     Actual Value\n","0   First number with matching width unit: 3.0 cen...         1.1 inch\n","1   First number with matching width unit: 7.0 cen...   7.0 centimetre\n","2   First number with matching item_weight unit: 7...       1 kilogram\n","3   First number with matching depth unit: 38.1 ce...  38.1 centimetre\n","4   First number with matching width unit: 3.0 cen...   3.0 centimetre\n","..                                                ...              ...\n","95  First number with matching width unit: 18.9 ce...  18.9 centimetre\n","96  First number with matching height unit: 12.0 c...  21.0 centimetre\n","97                                   No number found.        12.0 volt\n","98  First number with matching width unit: 36.0 ce...  29.0 centimetre\n","99  First number with matching width unit: 129.9 inch        29.9 inch\n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-67bf15a1-2463-422f-958c-119055cd2ac0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Predicted Value</th>\n","      <th>Actual Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>First number with matching width unit: 3.0 cen...</td>\n","      <td>1.1 inch</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>First number with matching width unit: 7.0 cen...</td>\n","      <td>7.0 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>First number with matching item_weight unit: 7...</td>\n","      <td>1 kilogram</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>First number with matching depth unit: 38.1 ce...</td>\n","      <td>38.1 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>First number with matching width unit: 3.0 cen...</td>\n","      <td>3.0 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>First number with matching width unit: 18.9 ce...</td>\n","      <td>18.9 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>First number with matching height unit: 12.0 c...</td>\n","      <td>21.0 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>No number found.</td>\n","      <td>12.0 volt</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>First number with matching width unit: 36.0 ce...</td>\n","      <td>29.0 centimetre</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>First number with matching width unit: 129.9 inch</td>\n","      <td>29.9 inch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67bf15a1-2463-422f-958c-119055cd2ac0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-67bf15a1-2463-422f-958c-119055cd2ac0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-67bf15a1-2463-422f-958c-119055cd2ac0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-943c1f8e-1722-459c-b782-c81182f7325e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-943c1f8e-1722-459c-b782-c81182f7325e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-943c1f8e-1722-459c-b782-c81182f7325e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"comparison_df","summary":"{\n  \"name\": \"comparison_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Predicted Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"First number with matching width unit: 3.0 centimetre\",\n          \"First number with matching width unit: 1152.4 centimetre\",\n          \"First number with matching height unit: 6.0 centimetre\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          \"7.92 inch\",\n          \"350 pound\",\n          \"5.0 centimetre\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# prompt: find the fraction of predicted vs actual value which are correctly predicted\n","\n","import pandas as pd\n","# Create lists to store results\n","predicted_values = []\n","actual_values = []\n","\n","# Iterate through each row in the dataframe\n","for index, row in train_data.iterrows():\n","    image_link = row['image_link']\n","    entity_name = row['entity_name']\n","    actual_value = row['entity_value']\n","    result = extract_entity_value(image_link, entity_name)\n","\n","    # Store predicted and actual values\n","    predicted_values.append(result)\n","    actual_values.append(actual_value)\n","\n","    print(f\"Image: {image_link}, Entity: {entity_name}, Result: {result}, Actual: {actual_value}\")\n","\n","# Create a DataFrame for side-by-side comparison\n","comparison_df = pd.DataFrame({'Predicted Value': predicted_values, 'Actual Value': actual_values})\n","\n","# Function to extract the number from the predicted value string\n","def extract_number(predicted_value):\n","    try:\n","        # Find the number using regex\n","        match = re.search(r'(\\d+\\.?\\d*)', predicted_value)\n","        if match:\n","            return float(match.group(1))\n","        else:\n","            return None\n","    except:\n","        return None\n","\n","# Apply the function to extract numbers from the predicted values\n","comparison_df['Predicted Number'] = comparison_df['Predicted Value'].apply(extract_number)\n","\n","# Apply the function to extract numbers from the actual values\n","comparison_df['Actual Number'] = comparison_df['Actual Value'].apply(lambda x: float(x.split()[0]) if isinstance(x, str) and x.split()[0].isdigit() else None)\n","\n","# Calculate the difference between predicted and actual values\n","comparison_df['Difference'] = abs(comparison_df['Predicted Number'] - comparison_df['Actual Number'])\n","\n","# Define a threshold for considering a prediction correct\n","threshold = 0.1  # Adjust this value as needed\n","\n","# Calculate the number of correct predictions\n","correct_predictions = comparison_df[comparison_df['Difference'] <= threshold].shape[0]\n","\n","# Calculate the fraction of correctly predicted values\n","fraction_correct = correct_predictions / len(comparison_df)\n","\n","print(f\"\\nFraction of correctly predicted values: {fraction_correct}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"ftTp4WGfZAlk","executionInfo":{"status":"error","timestamp":1726264676149,"user_tz":-330,"elapsed":1510,"user":{"displayName":"Nalin","userId":"12386870817090352164"}},"outputId":"970d9d0a-5da4-4a16-8a67-78d0ea8a9bc6"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-6e166884c598>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Iterate through each row in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimage_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mentity_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4EjAGTK6xBqM"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1vrzmassJ8DaWFLOHkS5LZIEdjoC2LZ-n","authorship_tag":"ABX9TyN550I4ZvEBQQxEouzWAQPl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}